{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from collections import deque\n",
    "import cluster_refinement as refine\n",
    "import spectral_embedding as se\n",
    "import pathfinders\n",
    "import random\n",
    "import example_graphs as examples\n",
    "import visual_aids as vis\n",
    "import random\n",
    "# other\n",
    "strategies = [\n",
    "        {'name': 'boundary first', 'weights': {'boundary': 1.0, 'deg_diff': 0.0}},\n",
    "        {'name': 'boundary last', 'weights': {'boundary': -1.0, 'deg_diff': 0.0}},\n",
    "        {'name': 'deg diff descending', 'weights': {'boundary': 0.0, 'deg_diff': 1.0}},\n",
    "        {'name': 'deg diff ascending', 'weights': {'boundary': 0.0, 'deg_diff': -1.0}},\n",
    "        {'name': '(1.0, 1.0)', 'weights': {'boundary': 1.0, 'deg_diff': 1.0}},\n",
    "        {'name': '(-1.0, -1.0)', 'weights': {'boundary': -1.0, 'deg_diff': -1.0}},\n",
    "        {'name': 'random', 'weights': None},\n",
    "        {'name': 'fiedler', 'weights': None},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data : ham_tests (list), nonham_tests (list of (name, graph))\n",
    "def generate_test_data(n):\n",
    "    from data import test_data\n",
    "    from example_graphs import generate_classic_nonhamiltonian_graphs\n",
    "    ham_tests = list(test_data.values())\n",
    "    nonham_tests = list(generate_classic_nonhamiltonian_graphs(n).items())\n",
    "    return ham_tests, nonham_tests\n",
    "ham_tests, nonham_tests = generate_test_data(20)\n",
    "def generate_random_sparse_graphs(N, n, p):\n",
    "    data = []\n",
    "    from example_graphs import test_graph_sparsity\n",
    "    for _ in range(N):\n",
    "        data.append(test_graph_sparsity(n,p))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_cheeger_split(G, frontier=None, min_size=2, cond_threshold=1, symmetry_tol=1, max_depth=3, current_depth=0, init_n=None):\n",
    "    if frontier is None:\n",
    "        frontier = []\n",
    "    n = G.number_of_nodes()\n",
    "    if init_n is None:\n",
    "        init_n = n\n",
    "    if n == 0 or n <= min_size or n < init_n / 4 or current_depth >= max_depth:\n",
    "        return {\n",
    "            'nodes': set(G.nodes()),\n",
    "            'frontier': frontier,\n",
    "            'graph': G,\n",
    "            'spectral': None,\n",
    "            'cheeger': None,\n",
    "            'symmetric': True,\n",
    "            'children': None\n",
    "        }\n",
    "    \n",
    "    cond, cut_set = refine.cheeger_cut(G)\n",
    "    boundary = refine.boundary_edges(G, cut_set)\n",
    "    new_frontier = frontier.copy() \n",
    "    new_frontier.append(boundary)\n",
    "    \n",
    "    if cond is None or cond > cond_threshold or cut_set == set(G.nodes()) or not cut_set:\n",
    "        return {\n",
    "            'nodes': set(G.nodes()),\n",
    "            'frontier': new_frontier,\n",
    "            'graph': G,\n",
    "            'spectral': None,\n",
    "            'cheeger': None,\n",
    "            'symmetric': True,\n",
    "            'children': None\n",
    "        }\n",
    "    \n",
    "    comp_left = G.subgraph(cut_set).copy()\n",
    "    comp_right = G.subgraph(set(G.nodes()) - cut_set).copy()\n",
    "    \n",
    "    left_spec = se.spectral_radius(comp_left)\n",
    "    right_spec = se.spectral_radius(comp_right)\n",
    "    left_cheeger, _ = refine.cheeger_cut(comp_left)\n",
    "    right_cheeger, _ = refine.cheeger_cut(comp_right)\n",
    "    \n",
    "    spectral_tuple = (left_spec, right_spec)\n",
    "    cheeger_tuple = (left_cheeger, right_cheeger)\n",
    "    \n",
    "    spec_diff = abs(left_spec - right_spec) if left_spec is not None and right_spec is not None else float('inf')\n",
    "    cheeger_diff = abs(left_cheeger - right_cheeger) if left_cheeger is not None and right_cheeger is not None else float('inf')\n",
    "    is_symmetric = (spec_diff < symmetry_tol) and (cheeger_diff < symmetry_tol)\n",
    "    \n",
    "    left_subtree = recursive_cheeger_split(comp_left, new_frontier, min_size, cond_threshold, symmetry_tol, max_depth, current_depth + 1, init_n)\n",
    "    right_subtree = recursive_cheeger_split(comp_right, new_frontier, min_size, cond_threshold, symmetry_tol, max_depth, current_depth + 1, init_n)\n",
    "    \n",
    "    if is_symmetric:\n",
    "        return {\n",
    "            'nodes': set(G.nodes()),\n",
    "            'frontier': new_frontier,\n",
    "            'graph': G,\n",
    "            'spectral': spectral_tuple,\n",
    "            'cheeger': cheeger_tuple,\n",
    "            'symmetric': True,\n",
    "            'children': [left_subtree, right_subtree]\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'nodes': set(G.nodes()),\n",
    "        'frontier': new_frontier,\n",
    "        'graph': G,\n",
    "        'spectral': spectral_tuple,\n",
    "        'cheeger': cheeger_tuple,\n",
    "        'symmetric': False,\n",
    "        'children': [left_subtree, right_subtree]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, graph in nonham_tests:\n",
    "    closed = refine.bondy_chvatal_closure(graph)\n",
    "    reduced = refine.aggressive_pruning_ordered(closed, weights={'boundary': -1.0, 'deg_diff': 0.0})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph size 3000 > 750: using k = 81 with QR approximation\n",
      "found clustering behavior on signless laplacian eigenvalues for 44 clusters\n"
     ]
    }
   ],
   "source": [
    "G = random.choice(ham_tests)\n",
    "data = se.fast_eigen_decomp(G)\n",
    "labels = se.get_partitions(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "82\n",
      "56\n",
      "71\n",
      "96\n",
      "65\n",
      "72\n",
      "72\n",
      "84\n",
      "51\n",
      "64\n",
      "65\n",
      "71\n",
      "60\n",
      "84\n",
      "52\n",
      "84\n",
      "59\n",
      "59\n",
      "84\n",
      "71\n",
      "65\n",
      "76\n",
      "65\n",
      "64\n",
      "67\n",
      "63\n",
      "51\n",
      "51\n",
      "69\n",
      "73\n",
      "69\n",
      "57\n",
      "73\n",
      "86\n",
      "61\n",
      "80\n",
      "63\n",
      "79\n",
      "55\n",
      "68\n",
      "64\n",
      "81\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "clusters = refine.labels_to_clusters(G, labels)\n",
    "closed_clusters = []\n",
    "for cluster in clusters.values():\n",
    "    cste, cut = refine.cheeger_cut(cluster)\n",
    "    if cste < 0.5:\n",
    "        \n",
    "    else:\n",
    "        cl_cluster = refine.bondy_chvatal_closure(cluster)\n",
    "        reduced = refine.aggressive_pruning_ordered(cl_cluster, weights={'boundary': -1.0, 'deg_diff': 0.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contract_cycles(G, cycles):\n",
    "    # Nodes that are in a cycle get mapped to a supernode label.\n",
    "    mapping = {}\n",
    "    for i, cycle in enumerate(cycles):\n",
    "        # Create a label for the supernode representing the cycle.\n",
    "        supernode = f\"supernode_{i}\"\n",
    "        for node in cycle:\n",
    "            mapping[node] = supernode\n",
    "    # For nodes not included in any cycle, map them to themselves.\n",
    "    for node in G.nodes():\n",
    "        if node not in mapping:\n",
    "            mapping[node] = node\n",
    "\n",
    "    # Now build the new graph using the mapping.\n",
    "    H = nx.Graph()\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        # Determine new endpoints based on the mapping.\n",
    "        new_u = mapping[u]\n",
    "        new_v = mapping[v]\n",
    "        # Avoid self-loops (edges within the same supernode)\n",
    "        if new_u == new_v:\n",
    "            continue\n",
    "        # Add the edge to the new graph. If multiple edges emerge between the same nodes,\n",
    "        # you might want to aggregate or simply ignore duplicates.\n",
    "        if H.has_edge(new_u, new_v):\n",
    "            # Optionally, aggregate attributes or count multiplicity.\n",
    "            continue\n",
    "        H.add_edge(new_u, new_v, **data)\n",
    "    return H\n",
    "\n",
    "Gcontracted = contract_cycles(G, cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def has_hamiltonian_path_via_cycle(G, A, cycle_nodes, B):\n",
    "    \"\"\"\n",
    "    Check whether there is a Hamiltonian path from A to B through the cycle.\n",
    "    \n",
    "    The idea is to verify that the cycle (or the set of nodes from which\n",
    "    the supernode was built) can be traversed in such a way that A and B\n",
    "    (or their connection points) are linked by a path that visits every vertex \n",
    "    of the cycle once.\n",
    "    \n",
    "    For demonstration purposes, this function returns True if:\n",
    "      - A and B both connect to some nodes in cycle_nodes\n",
    "      - And (optionally) if the connections appear 'symmetric enough'\n",
    "      \n",
    "    In a rigorous implementation, you would apply a P贸sa rotation technique\n",
    "    or another method to verify the Hamiltonicity condition.\n",
    "    \"\"\"\n",
    "    # For simplicity, check that at least one node in the cycle connects to A\n",
    "    # and one (potentially different) node connects to B.\n",
    "    connects_A = any(G.has_edge(A, node) for node in cycle_nodes)\n",
    "    connects_B = any(G.has_edge(B, node) for node in cycle_nodes)\n",
    "    \n",
    "    # This is a very lenient condition. Replace with P贸sa's rotation logic as needed.\n",
    "    return connects_A and connects_B\n",
    "\n",
    "def contract_supernodes_via_posa(G, cycles):\n",
    "    \"\"\"\n",
    "    For each cycle (a list of nodes) provided in `cycles`, we assume it has been\n",
    "    contracted to a supernode in G with the name 'supernode_{i}'.\n",
    "    \n",
    "    This function goes over each such cycle/supernode and attempts to contract\n",
    "    the chain A - supernode - B into a single edge A-B. The contraction is done\n",
    "    only when a Hamiltonian path exists via the cycle as confirmed by a P贸sa rotation\n",
    "    based check (or a simplified version thereof).\n",
    "    \n",
    "    The function returns a new graph with those valid contractions.\n",
    "    \"\"\"\n",
    "    # Create a mapping from the cycle list to its supernode label.\n",
    "    mapping = {}\n",
    "    for i, cycle in enumerate(cycles):\n",
    "        supernode = f\"supernode_{i}\"\n",
    "        for node in cycle:\n",
    "            mapping[node] = supernode\n",
    "    \n",
    "    H = nx.Graph()\n",
    "    # First, build graph H by mapping nodes from G to supernodes when needed.\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        new_u = mapping.get(u, u)\n",
    "        new_v = mapping.get(v, v)\n",
    "        if new_u != new_v:\n",
    "            H.add_edge(new_u, new_v, **data)\n",
    "    \n",
    "    # Now look for cases where a supernode connects exactly two distinct nodes: A and B.\n",
    "    to_contract = []\n",
    "    for node in list(H.nodes()):\n",
    "        # Only check nodes that are supernodes.\n",
    "        if isinstance(node, str) and node.startswith(\"supernode_\"):\n",
    "            neighbors = list(H.neighbors(node))\n",
    "            if len(neighbors) == 2:\n",
    "                A, B = neighbors\n",
    "                # Retrieve the original cycle that formed this supernode.\n",
    "                cycle_index = int(node.split(\"_\")[1])\n",
    "                cycle_nodes = cycles[cycle_index]\n",
    "                # Use P贸sa's rotation (or a simplified check) to verify Hamiltonian connection.\n",
    "                if has_hamiltonian_path_via_cycle(G, A, cycle_nodes, B):\n",
    "                    to_contract.append((node, A, B))\n",
    "    \n",
    "    # For each valid contraction, remove the supernode and add a direct edge A-B.\n",
    "    for supernode, A, B in to_contract:\n",
    "        if H.has_node(supernode):\n",
    "            H.remove_node(supernode)\n",
    "            if not H.has_edge(A, B):\n",
    "                H.add_edge(A, B)\n",
    "    \n",
    "    return H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1\n",
      "extracted cycle: [2000, 1792, 1791, 1790, 1789, 1203, 1956, 1957, 1236, 15, 1980, 1981, 1242, 1982, 1243, 1983, 1244, 1984, 503, 838, 1989, 1245, 1990, 1991, 1992, 1246, 1993, 1994, 1995, 1171, 1691, 1692, 1693, 1173, 1917, 1918, 499, 1919, 500, 1920, 1921, 1229, 1922, 501, 1988, 1184, 1725, 773, 774, 1941, 998, 1202, 1799, 1798, 1797, 4, 1954, 1235, 1955, 881, 371, 1985, 1986, 1987, 504, 1104, 1682, 748, 749, 1877, 747, 163, 1882, 1883, 1239, 1971, 1972, 353, 985, 1973, 1974, 1240, 1975, 1976, 1241, 1977, 1978, 1979, 899, 982, 1909, 1159, 979, 1910, 1227, 1911, 1912, 1228, 1913, 1914, 852, 490, 1915, 1916, 49, 1933, 1934, 5, 1648, 1649, 459, 1650, 1160, 1855, 1035, 1312, 388, 1939, 1940, 863, 913, 1005, 1226, 1908, 1225, 1907, 1906, 173, 1905, 1186, 1734, 1185, 464, 1861, 1860, 1232, 1936, 1937, 1938, 1101, 1474, 1039, 927, 1753, 1754, 478, 1881, 1880, 1879, 1878, 752, 751, 1037, 1317, 127, 1444, 1445, 1089, 452, 1872, 497, 46, 1832, 1209, 1831, 1161, 1654, 460, 1809, 1133, 967, 1034, 1930, 502, 1931, 1932, 1231, 1292, 1291, 1025, 921, 867, 154, 1626, 1150, 1627, 1628, 1629, 1630, 455, 1549, 1010, 115, 1303, 114, 761, 1899, 48, 1388, 350, 438, 810, 447, 1723, 1183, 1724, 1147, 1614, 1059, 1373, 44, 195, 477, 1752, 1751, 1750, 1749, 1748, 476, 489, 382, 1862, 494, 1873, 1220, 145, 351, 1888, 1222, 1889, 1890, 1891, 1892, 1893, 1894, 1223, 1895, 1896, 498, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1032, 1309, 856, 830, 817, 1833, 1834, 839, 42, 1636, 1151, 1637, 1152, 25, 1961, 1962, 1963, 1237, 1964, 1238, 1965, 1966, 175, 1998, 1997, 1996, 1219, 1870, 1869, 1218, 1868, 1217, 1867, 742, 83, 962, 1126, 963, 1825, 487, 1839, 723, 724, 1097, 1840, 1212, 1841, 1842, 1213, 492, 161, 1960, 789, 6, 581, 1, 883, 953, 1102, 1599, 1600, 144, 545, 1803, 1804, 1805, 483, 1806, 45, 1465, 1466, 1467, 421, 434, 1530, 1124, 1793, 1794, 1204, 1795, 170, 1821, 1820, 1819, 1818, 1817, 404, 240, 1853, 493, 1854, 1098, 1459, 143, 1857, 1858, 1146, 471, 1859, 1216, 1566, 442, 1200, 1808, 169, 1156, 1642, 1155, 1643, 987, 29, 1234, 1953, 779, 780, 67, 479, 1761, 1760, 1759, 472, 1730, 1731, 433, 949, 1099, 950, 294, 1942, 1233, 101, 1970, 1969, 1968, 1967, 794, 797, 801, 806, 399, 1349, 1348, 119, 13, 1404, 1405, 474, 1741, 696, 695, 304, 980, 125, 1476, 1475, 844, 463, 1827, 845, 72, 618, 428, 1602, 1603, 1145, 1694, 1695, 1696, 1697, 1174, 1735, 1736, 133, 1438, 1041, 327, 1777, 1778, 168, 1838, 1211, 1837, 359, 280, 898, 1787, 1786, 1201, 1785, 482, 1784, 1783, 481, 1260, 365, 278, 312, 1929, 1928, 1230, 1927, 1926, 1925, 174, 1270, 1018, 131, 1770, 1771, 1772, 480, 1863, 1864, 495, 1865, 1866, 211, 599, 212, 1849, 1214, 1850, 1851, 1215, 1852, 414, 151, 1619, 1620, 451, 1763, 1192, 1810, 1811, 1205, 1822, 1207, 1823, 486, 674, 1163, 1658, 158, 782, 1944, 1943, 109, 1288, 1289, 1290, 167, 301, 966, 1132, 1902, 1903, 1904, 1103, 954, 885, 1666, 1083, 32, 1308, 1031, 923, 309, 993, 1738, 1187, 1739, 1740, 1074, 1415, 162, 1733, 473, 1311, 1033, 90, 300, 156, 1641, 1154, 1762, 1113, 1499, 1500, 429, 1843]\n",
      "updated size: 1464\n",
      "iteration 2\n",
      "extracted cycle: [1135, 1567, 1568, 1061, 468, 1690, 1689, 1688, 1044, 1337, 395, 53, 1813, 1206, 1814, 485, 1901, 1224, 1392, 150, 1653, 1652, 157, 1788, 1007, 57, 446, 1647, 1158, 1780, 1197, 1781, 1198, 1782, 1199, 366, 1263, 929, 1042, 1336, 1043, 1613, 147, 104, 1258, 364, 611]\n",
      "updated size: 1417\n",
      "iteration 3\n",
      "extracted cycle: [1999, 1137, 1575, 1576, 910, 142, 1581, 1580, 1139, 343, 999, 1685, 1013, 1251, 124, 1757, 1191, 137, 1494, 1495, 40, 77, 896, 976, 1153, 1826, 488, 367, 1264, 368, 243, 257, 800, 805, 1747, 1746, 165, 1898, 1897, 1166, 1670, 1671, 1167, 1672, 1673, 1168, 984, 1720, 1182, 1719, 555, 279, 894, 1589, 1143, 1172, 107, 938, 378, 1279, 1022, 1280, 393, 1364, 1054, 87, 586, 374, 1667, 462, 826, 843, 43, 1699, 1175, 1704, 1177, 859, 908, 860, 403, 470, 1722, 784, 402, 1357, 401, 1605, 1606, 1607, 448, 1712, 469, 1142, 1767, 1768, 1194, 159, 1952]\n",
      "updated size: 1318\n",
      "iteration 4\n",
      "extracted cycle: [738, 739, 740, 289, 1496, 1110, 1705, 1706, 1178, 96, 1886, 1887, 206, 573, 310, 1675, 1676, 776, 775, 303, 975, 1484, 425, 70, 1631, 1632, 1633, 1634, 1635, 293, 943, 1829, 1208, 1828, 47, 1847, 1848, 172, 1338, 1045, 932, 1524, 1121, 960, 887, 903, 989, 1698]\n",
      "updated size: 1270\n",
      "iteration 5\n",
      "extracted cycle: [245, 722, 1026, 1299, 112, 1282, 1283, 467, 1687, 516]\n",
      "updated size: 1260\n",
      "iteration 6\n",
      "extracted cycle: [802, 811, 986, 1505, 1115, 123, 526, 358, 339, 1129, 1550, 440, 1565, 441, 1540, 1539, 322, 1072, 1410, 129, 381, 454, 1656, 461, 270, 847, 1525, 1122, 397, 1340, 933, 1046, 1344, 1345, 1346, 1047, 1612, 146, 1008, 116, 1327, 394, 804, 813, 828, 1796]\n",
      "updated size: 1214\n",
      "iteration 7\n",
      "iteration 8\n",
      "extracted cycle: [585, 584, 634, 432, 1512, 1511, 134, 1440, 1441, 1087, 1800, 1801, 1802, 1180, 354, 505, 325, 1079, 1429, 1430, 430, 1560, 1561, 643, 255, 1700, 1701, 1176, 475, 1745]\n",
      "updated size: 1181\n",
      "iteration 9\n",
      "extracted cycle: [171, 1835, 1210, 615, 221, 658, 290, 934, 427, 1490, 1107, 1491, 1108, 1534, 1165, 1669, 1064, 1376, 1063, 1755, 1756, 1190, 600, 601, 139, 1900]\n",
      "updated size: 1155\n",
      "iteration 10\n",
      "extracted cycle: [1140, 1582, 1141, 1616, 450, 1727, 1728, 905, 858, 832, 819, 807, 386, 1307, 809, 823]\n",
      "updated size: 1139\n",
      "iteration 11\n",
      "extracted cycle: [389, 1316, 991, 904, 550, 548, 1297, 110, 1554, 41, 1563, 1134, 1193, 1766, 148, 1615, 149, 35, 1412, 413, 1498, 1112, 958, 135, 680, 1659, 1157, 1646, 272, 861, 909, 1002]\n",
      "updated size: 1107\n",
      "iteration 12\n",
      "extracted cycle: [1070, 1397, 1075, 1418, 1419, 1420, 1421, 1076, 89, 882, 952, 1765, 166, 1935]\n",
      "updated size: 1093\n",
      "iteration 13\n",
      "extracted cycle: [1959, 872, 930, 108, 1285, 1024, 1286, 757, 410, 772, 771, 770, 769, 768, 766, 1473, 38, 620, 1729, 1181, 1717, 1718, 691, 132, 1564, 965, 92, 1123, 1527, 1528, 1529, 36, 1442, 1088, 1591, 1592, 1593, 1594, 445, 1542, 2, 1131, 1553, 1050, 1354, 760, 758, 1844, 1845, 840, 824, 263, 654, 656, 1711, 969, 1136, 1609, 1610, 1015, 1261, 177, 56, 594, 595, 1443, 628, 630, 340, 1130, 341, 1923, 1924, 875, 937, 1703, 160, 1707, 1708, 1179, 1709, 1710, 893, 849, 834, 1093, 1464, 1463, 1462, 418, 808, 821, 1517, 1518, 140, 733, 11, 3, 1531, 1532, 1533, 417, 1437, 1085, 1436, 1435, 959, 936, 1052, 1359, 130, 1713, 1714, 788, 787, 106, 1269, 524, 247, 391, 1092, 1556, 1557, 1558, 1559]\n",
      "updated size: 968\n",
      "iteration 14\n",
      "extracted cycle: [785, 510, 333, 1096, 1458, 1081, 1432, 589, 588, 84, 994, 906, 1885, 1884, 1221, 1775, 1196, 1856, 854, 725, 248, 563, 1329, 117, 306, 1773, 1195, 1774]\n",
      "updated size: 940\n",
      "iteration 15\n",
      "extracted cycle: [1958, 1028, 1301, 1302, 113, 1109, 1493]\n",
      "updated size: 933\n",
      "iteration 16\n",
      "extracted cycle: [812, 825, 841, 874, 1640, 1189, 1744, 28, 681, 682, 122, 1375, 1062, 1060, 1374, 138, 1816, 1815, 712, 373, 1051, 1355, 1356, 415, 1425, 426, 1488, 1489, 1188, 1743, 164, 1779, 968, 1117, 1510, 1116, 1874, 1875, 1876, 496, 1871]\n",
      "updated size: 892\n",
      "iteration 17\n",
      "iteration 18\n",
      "extracted cycle: [178, 287, 926, 1036, 1535]\n",
      "updated size: 885\n",
      "iteration 19\n",
      "extracted cycle: [765, 764, 1611, 1053, 1362, 443, 1758, 707, 706]\n",
      "updated size: 876\n",
      "iteration 20\n",
      "extracted cycle: [918, 1020, 1483, 1482, 136, 1481, 1480, 424, 1479, 39, 637, 86, 1638, 1639, 155, 857, 831, 686, 262, 33, 1368, 1057, 1369, 1370, 1058, 37, 1453, 1095, 332, 1585]\n",
      "updated size: 846\n",
      "iteration 21\n",
      "extracted cycle: [529, 530, 199, 708, 61, 256, 796, 901, 855, 1249, 102, 1080, 1570, 14, 1577, 651, 650, 16, 1586, 1587, 1588]\n",
      "updated size: 825\n",
      "iteration 22\n"
     ]
    }
   ],
   "source": [
    "def loop_extract(G, contracted, n):\n",
    "    A = se.to_adjacency(contracted)\n",
    "    _,fiedler,_ = se.power_method(A)\n",
    "    cycles = pathfinders.greedy_partial_cycle_extractor(G, fiedler)\n",
    "    contracted_new = contract_cycles(G, cycles)\n",
    "    if len(contracted)<5 or np.abs(contracted_new.number_of_nodes()-contracted.number_of_nodes())<n:\n",
    "        return contracted\n",
    "    return loop_extract(G, contracted_new, n)\n",
    "n = np.log(G.number_of_nodes())*200\n",
    "contracted = loop_extract(G, G, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 2000 nodes and 3996 edges\n",
      "iteration 1\n",
      "extracted cycle: [1792, 1791, 1790, 1789, 1203, 1956, 1957, 1236, 15, 1980, 1981, 1242, 1982, 1243, 1983, 1244, 1984, 503, 838, 1989, 1245, 1990, 1991, 1992, 1246, 1993, 1994, 1995, 1171, 1691, 1692, 1693, 1173, 1917, 1918, 499, 1919, 500, 1920, 1921, 1229, 1922, 501, 1988, 1184, 1725, 773, 774, 1941, 998, 1202, 1799, 1798, 1797, 4, 1954, 1235, 1955, 881, 371, 1985, 1986, 1987, 504, 1104, 1682, 748, 749, 1877, 747, 163, 1882, 1883, 1239, 1971, 1972, 353, 985, 1973, 1974, 1240, 1975, 1976, 1241, 1977, 1978, 1979, 899, 982, 1909, 1159, 979, 1910, 1227, 1911, 1912, 1228, 1913, 1914, 852, 490, 1915, 1916, 49, 1933, 1934, 5, 1648, 1649, 459, 1650, 1160, 1855, 1035, 1312, 388, 1939, 1940, 863, 913, 1005, 1226, 1908, 1225, 1907, 1906, 173, 1905, 1186, 1734, 1185, 464, 1861, 1860, 1232, 1936, 1937, 1938, 1101, 1474, 1039, 927, 1753, 1754, 478, 1881, 1880, 1879, 1878, 752, 751, 1037, 1317, 127, 1444, 1445, 1089, 452, 1872, 497, 46, 1832, 1209, 1831, 1161, 1654, 460, 1809, 1133, 967, 1034, 1930, 502, 1931, 1932, 1231, 1292, 1291, 1025, 921, 867, 154, 1626, 1150, 1627, 1628, 1629, 1630, 455, 1549, 1010, 115, 1303, 114, 761, 1899, 48, 1388, 350, 438, 810, 447, 1723, 1183, 1724, 1147, 1614, 1059, 1373, 44, 195, 477, 1752, 1751, 1750, 1749, 1748, 476, 489, 382, 1862, 494, 1873, 1220, 145, 351, 1888, 1222, 1889, 1890, 1891, 1892, 1893, 1894, 1223, 1895, 1896, 498, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1032, 1309, 856, 830, 817, 1833, 1834, 839, 42, 1636, 1151, 1637, 1152, 25, 1961, 1962, 1963, 1237, 1964, 1238, 1965, 1966, 175, 1998, 1997, 1996, 1219, 1870, 1869, 1218, 1868, 1217, 1867, 742, 83, 962, 1126, 963, 1825, 487, 1839, 723, 724, 1097, 1840, 1212, 1841, 1842, 1213, 492, 161, 1960, 789, 6, 581, 1, 883, 953, 1102, 1599, 1600, 144, 545, 1803, 1804, 1805, 483, 1806, 45, 1465, 1466, 1467, 421, 434, 1530, 1124, 1793, 1794, 1204, 1795, 170, 1821, 1820, 1819, 1818, 1817, 404, 240, 1853, 493, 1854, 1098, 1459, 143, 1857, 1858, 1146, 471, 1859, 1216, 1566, 442, 1200, 1808, 169, 1156, 1642, 1155, 1643, 987, 29, 1234, 1953, 779, 780, 67, 479, 1761, 1760, 1759, 472, 1730, 1731, 433, 949, 1099, 950, 294, 1942, 1233, 101, 1970, 1969, 1968, 1967, 794, 797, 801, 806, 399, 1349, 1348, 119, 13, 1404, 1405, 474, 1741, 696, 695, 304, 980, 125, 1476, 1475, 844, 463, 1827, 845, 72, 618, 428, 1602, 1603, 1145, 1694, 1695, 1696, 1697, 1174, 1735, 1736, 133, 1438, 1041, 327, 1777, 1778, 168, 1838, 1211, 1837, 359, 280, 898, 1787, 1786, 1201, 1785, 482, 1784, 1783, 481, 1260, 365, 278, 312, 1929, 1928, 1230, 1927, 1926, 1925, 174, 1270, 1018, 131, 1770, 1771, 1772, 480, 1863, 1864, 495, 1865, 1866, 211, 599, 212, 1849, 1214, 1850, 1851, 1215, 1852, 414, 151, 1619, 1620, 451, 1763, 1192, 1810, 1811, 1205, 1822, 1207, 1823, 486, 674, 1163, 1658, 158, 782, 1944, 1943, 109, 1288, 1289, 1290, 167, 301, 966, 1132, 1902, 1903, 1904, 1103, 954, 885, 1666, 1083, 32, 1308, 1031, 923, 309, 993, 1738, 1187, 1739, 1740, 1074, 1415, 162, 1733, 473, 1311, 1033, 90, 300, 156, 1641, 1154, 1762, 1113, 1499, 1500, 429, 1843]\n",
      "updated size: 1463\n",
      "iteration 2\n",
      "extracted cycle: [1135, 1567, 1568, 1061, 468, 1690, 1689, 1688, 1044, 1337, 395, 53, 1813, 1206, 1814, 485, 1901, 1224, 1392, 150, 1653, 1652, 157, 1788, 1007, 57, 446, 1647, 1158, 1780, 1197, 1781, 1198, 1782, 1199, 366, 1263, 929, 1042, 1336, 1043, 1613, 147, 104, 1258, 364, 611]\n",
      "updated size: 1416\n",
      "iteration 3\n",
      "extracted cycle: [1137, 1575, 1576, 910, 142, 1581, 1580, 1139, 343, 999, 1685, 1013, 1251, 124, 1757, 1191, 137, 1494, 1495, 40, 77, 896, 976, 1153, 1826, 488, 367, 1264, 368, 243, 257, 800, 805, 1747, 1746, 165, 1898, 1897, 1166, 1670, 1671, 1167, 1672, 1673, 1168, 984, 1720, 1182, 1719, 555, 279, 894, 1589, 1143, 1172, 107, 938, 378, 1279, 1022, 1280, 393, 1364, 1054, 87, 586, 374, 1667, 462, 826, 843, 43, 1699, 1175, 1704, 1177, 859, 908, 860, 403, 470, 1722, 784, 402, 1357, 401, 1605, 1606, 1607, 448, 1712, 469, 1142, 1767, 1768, 1194, 159, 1952]\n",
      "updated size: 1318\n",
      "iteration 4\n",
      "extracted cycle: [738, 739, 740, 289, 1496, 1110, 1705, 1706, 1178, 96, 1886, 1887, 206, 573, 310, 1675, 1676, 776, 775, 303, 975, 1484, 425, 70, 1631, 1632, 1633, 1634, 1635, 293, 943, 1829, 1208, 1828, 47, 1847, 1848, 172, 1338, 1045, 932, 1524, 1121, 960, 887, 903, 989, 1698]\n",
      "updated size: 1270\n",
      "iteration 5\n",
      "extracted cycle: [245, 722, 1026, 1299, 112, 1282, 1283, 467, 1687, 516]\n",
      "updated size: 1260\n",
      "iteration 6\n",
      "extracted cycle: [802, 811, 986, 1505, 1115, 123, 526, 358, 339, 1129, 1550, 440, 1565, 441, 1540, 1539, 322, 1072, 1410, 129, 381, 454, 1656, 461, 270, 847, 1525, 1122, 397, 1340, 933, 1046, 1344, 1345, 1346, 1047, 1612, 146, 1008, 116, 1327, 394, 804, 813, 828, 1796]\n",
      "updated size: 1214\n",
      "iteration 7\n",
      "iteration 8\n",
      "extracted cycle: [585, 584, 634, 432, 1512, 1511, 134, 1440, 1441, 1087, 1800, 1801, 1802, 1180, 354, 505, 325, 1079, 1429, 1430, 430, 1560, 1561, 643, 255, 1700, 1701, 1176, 475, 1745]\n",
      "updated size: 1181\n",
      "iteration 9\n",
      "extracted cycle: [171, 1835, 1210, 615, 221, 658, 290, 934, 427, 1490, 1107, 1491, 1108, 1534, 1165, 1669, 1064, 1376, 1063, 1755, 1756, 1190, 600, 601, 139, 1900]\n",
      "updated size: 1155\n",
      "iteration 10\n",
      "extracted cycle: [1140, 1582, 1141, 1616, 450, 1727, 1728, 905, 858, 832, 819, 807, 386, 1307, 809, 823]\n",
      "updated size: 1139\n",
      "iteration 11\n",
      "extracted cycle: [389, 1316, 991, 904, 550, 548, 1297, 110, 1554, 41, 1563, 1134, 1193, 1766, 148, 1615, 149, 35, 1412, 413, 1498, 1112, 958, 135, 680, 1659, 1157, 1646, 272, 861, 909, 1002]\n",
      "updated size: 1107\n",
      "iteration 12\n",
      "extracted cycle: [1070, 1397, 1075, 1418, 1419, 1420, 1421, 1076, 89, 882, 952, 1765, 166, 1935]\n",
      "updated size: 1093\n",
      "iteration 13\n",
      "extracted cycle: [1959, 872, 930, 108, 1285, 1024, 1286, 757, 410, 772, 771, 770, 769, 768, 766, 1473, 38, 620, 1729, 1181, 1717, 1718, 691, 132, 1564, 965, 92, 1123, 1527, 1528, 1529, 36, 1442, 1088, 1591, 1592, 1593, 1594, 445, 1542, 2, 1131, 1553, 1050, 1354, 760, 758, 1844, 1845, 840, 824, 263, 654, 656, 1711, 969, 1136, 1609, 1610, 1015, 1261, 177, 56, 594, 595, 1443, 628, 630, 340, 1130, 341, 1923, 1924, 875, 937, 1703, 160, 1707, 1708, 1179, 1709, 1710, 893, 849, 834, 1093, 1464, 1463, 1462, 418, 808, 821, 1517, 1518, 140, 733, 11, 3, 1531, 1532, 1533, 417, 1437, 1085, 1436, 1435, 959, 936, 1052, 1359, 130, 1713, 1714, 788, 787, 106, 1269, 524, 247, 391, 1092, 1556, 1557, 1558, 1559]\n",
      "updated size: 968\n",
      "iteration 14\n",
      "extracted cycle: [785, 510, 333, 1096, 1458, 1081, 1432, 589, 588, 84, 994, 906, 1885, 1884, 1221, 1775, 1196, 1856, 854, 725, 248, 563, 1329, 117, 306, 1773, 1195, 1774]\n",
      "updated size: 940\n",
      "iteration 15\n",
      "extracted cycle: [1958, 1028, 1301, 1302, 113, 1109, 1493]\n",
      "updated size: 933\n",
      "iteration 16\n",
      "extracted cycle: [812, 825, 841, 874, 1640, 1189, 1744, 28, 681, 682, 122, 1375, 1062, 1060, 1374, 138, 1816, 1815, 712, 373, 1051, 1355, 1356, 415, 1425, 426, 1488, 1489, 1188, 1743, 164, 1779, 968, 1117, 1510, 1116, 1874, 1875, 1876, 496, 1871]\n",
      "updated size: 892\n",
      "iteration 17\n",
      "iteration 18\n",
      "extracted cycle: [178, 287, 926, 1036, 1535]\n",
      "updated size: 885\n",
      "iteration 19\n",
      "extracted cycle: [765, 764, 1611, 1053, 1362, 443, 1758, 707, 706]\n",
      "updated size: 876\n",
      "iteration 20\n",
      "extracted cycle: [918, 1020, 1483, 1482, 136, 1481, 1480, 424, 1479, 39, 637, 86, 1638, 1639, 155, 857, 831, 686, 262, 33, 1368, 1057, 1369, 1370, 1058, 37, 1453, 1095, 332, 1585]\n",
      "updated size: 846\n",
      "iteration 21\n",
      "extracted cycle: [529, 530, 199, 708, 61, 256, 796, 901, 855, 1249, 102, 1080, 1570, 14, 1577, 651, 650, 16, 1586, 1587, 1588]\n",
      "updated size: 825\n",
      "iteration 22\n",
      "iteration 1\n",
      "extracted cycle: [1792, 1791, 1790, 1789, 1203, 1956, 1957, 1236, 15, 1980, 1981, 1242, 1982, 1243, 1983, 1244, 1984, 503, 838, 1989, 1245, 1990, 1991, 1992, 1246, 1993, 1994, 1995, 1171, 1691, 1692, 1693, 1173, 1917, 1918, 499, 1919, 500, 1920, 1921, 1229, 1922, 501, 1988, 1184, 1725, 773, 774, 1941, 998, 1202, 1799, 1798, 1797, 4, 1954, 1235, 1955, 881, 371, 1985, 1986, 1987, 504, 1104, 1682, 748, 749, 1877, 747, 163, 1882, 1883, 1239, 1971, 1972, 353, 985, 1973, 1974, 1240, 1975, 1976, 1241, 1977, 1978, 1979, 899, 982, 1909, 1159, 979, 1910, 1227, 1911, 1912, 1228, 1913, 1914, 852, 490, 1915, 1916, 49, 1933, 1934, 5, 1648, 1649, 459, 1650, 1160, 1855, 1035, 1312, 388, 1939, 1940, 863, 913, 1005, 1226, 1908, 1225, 1907, 1906, 173, 1905, 1186, 1734, 1185, 464, 1861, 1860, 1232, 1936, 1937, 1938, 1101, 1474, 1039, 927, 1753, 1754, 478, 1881, 1880, 1879, 1878, 752, 751, 1037, 1317, 127, 1444, 1445, 1089, 452, 1872, 497, 46, 1832, 1209, 1831, 1161, 1654, 460, 1809, 1133, 967, 1034, 1930, 502, 1931, 1932, 1231, 1292, 1291, 1025, 921, 867, 154, 1626, 1150, 1627, 1628, 1629, 1630, 455, 1549, 1010, 115, 1303, 114, 761, 1899, 48, 1388, 350, 438, 810, 447, 1723, 1183, 1724, 1147, 1614, 1059, 1373, 44, 195, 477, 1752, 1751, 1750, 1749, 1748, 476, 489, 382, 1862, 494, 1873, 1220, 145, 351, 1888, 1222, 1889, 1890, 1891, 1892, 1893, 1894, 1223, 1895, 1896, 498, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1032, 1309, 856, 830, 817, 1833, 1834, 839, 42, 1636, 1151, 1637, 1152, 25, 1961, 1962, 1963, 1237, 1964, 1238, 1965, 1966, 175, 1998, 1997, 1996, 1219, 1870, 1869, 1218, 1868, 1217, 1867, 742, 83, 962, 1126, 963, 1825, 487, 1839, 723, 724, 1097, 1840, 1212, 1841, 1842, 1213, 492, 161, 1960, 789, 6, 581, 1, 883, 953, 1102, 1599, 1600, 144, 545, 1803, 1804, 1805, 483, 1806, 45, 1465, 1466, 1467, 421, 434, 1530, 1124, 1793, 1794, 1204, 1795, 170, 1821, 1820, 1819, 1818, 1817, 404, 240, 1853, 493, 1854, 1098, 1459, 143, 1857, 1858, 1146, 471, 1859, 1216, 1566, 442, 1200, 1808, 169, 1156, 1642, 1155, 1643, 987, 29, 1234, 1953, 779, 780, 67, 479, 1761, 1760, 1759, 472, 1730, 1731, 433, 949, 1099, 950, 294, 1942, 1233, 101, 1970, 1969, 1968, 1967, 794, 797, 801, 806, 399, 1349, 1348, 119, 13, 1404, 1405, 474, 1741, 696, 695, 304, 980, 125, 1476, 1475, 844, 463, 1827, 845, 72, 618, 428, 1602, 1603, 1145, 1694, 1695, 1696, 1697, 1174, 1735, 1736, 133, 1438, 1041, 327, 1777, 1778, 168, 1838, 1211, 1837, 359, 280, 898, 1787, 1786, 1201, 1785, 482, 1784, 1783, 481, 1260, 365, 278, 312, 1929, 1928, 1230, 1927, 1926, 1925, 174, 1270, 1018, 131, 1770, 1771, 1772, 480, 1863, 1864, 495, 1865, 1866, 211, 599, 212, 1849, 1214, 1850, 1851, 1215, 1852, 414, 151, 1619, 1620, 451, 1763, 1192, 1810, 1811, 1205, 1822, 1207, 1823, 486, 674, 1163, 1658, 158, 782, 1944, 1943, 109, 1288, 1289, 1290, 167, 301, 966, 1132, 1902, 1903, 1904, 1103, 954, 885, 1666, 1083, 32, 1308, 1031, 923, 309, 993, 1738, 1187, 1739, 1740, 1074, 1415, 162, 1733, 473, 1311, 1033, 90, 300, 156, 1641, 1154, 1762, 1113, 1499, 1500, 429, 1843]\n",
      "updated size: 1463\n",
      "iteration 2\n",
      "extracted cycle: [1135, 1567, 1568, 1061, 468, 1690, 1689, 1688, 1044, 1337, 395, 53, 1813, 1206, 1814, 485, 1901, 1224, 1392, 150, 1653, 1652, 157, 1788, 1007, 57, 446, 1647, 1158, 1780, 1197, 1781, 1198, 1782, 1199, 366, 1263, 929, 1042, 1336, 1043, 1613, 147, 104, 1258, 364, 611]\n",
      "updated size: 1416\n",
      "iteration 3\n",
      "extracted cycle: [1137, 1575, 1576, 910, 142, 1581, 1580, 1139, 343, 999, 1685, 1013, 1251, 124, 1757, 1191, 137, 1494, 1495, 40, 77, 896, 976, 1153, 1826, 488, 367, 1264, 368, 243, 257, 800, 805, 1747, 1746, 165, 1898, 1897, 1166, 1670, 1671, 1167, 1672, 1673, 1168, 984, 1720, 1182, 1719, 555, 279, 894, 1589, 1143, 1172, 107, 938, 378, 1279, 1022, 1280, 393, 1364, 1054, 87, 586, 374, 1667, 462, 826, 843, 43, 1699, 1175, 1704, 1177, 859, 908, 860, 403, 470, 1722, 784, 402, 1357, 401, 1605, 1606, 1607, 448, 1712, 469, 1142, 1767, 1768, 1194, 159, 1952]\n",
      "updated size: 1318\n",
      "iteration 4\n",
      "extracted cycle: [738, 739, 740, 289, 1496, 1110, 1705, 1706, 1178, 96, 1886, 1887, 206, 573, 310, 1675, 1676, 776, 775, 303, 975, 1484, 425, 70, 1631, 1632, 1633, 1634, 1635, 293, 943, 1829, 1208, 1828, 47, 1847, 1848, 172, 1338, 1045, 932, 1524, 1121, 960, 887, 903, 989, 1698]\n",
      "updated size: 1270\n",
      "iteration 5\n",
      "extracted cycle: [245, 722, 1026, 1299, 112, 1282, 1283, 467, 1687, 516]\n",
      "updated size: 1260\n",
      "iteration 6\n",
      "extracted cycle: [802, 811, 986, 1505, 1115, 123, 526, 358, 339, 1129, 1550, 440, 1565, 441, 1540, 1539, 322, 1072, 1410, 129, 381, 454, 1656, 461, 270, 847, 1525, 1122, 397, 1340, 933, 1046, 1344, 1345, 1346, 1047, 1612, 146, 1008, 116, 1327, 394, 804, 813, 828, 1796]\n",
      "updated size: 1214\n",
      "iteration 7\n",
      "iteration 8\n",
      "extracted cycle: [585, 584, 634, 432, 1512, 1511, 134, 1440, 1441, 1087, 1800, 1801, 1802, 1180, 354, 505, 325, 1079, 1429, 1430, 430, 1560, 1561, 643, 255, 1700, 1701, 1176, 475, 1745]\n",
      "updated size: 1181\n",
      "iteration 9\n",
      "extracted cycle: [171, 1835, 1210, 615, 221, 658, 290, 934, 427, 1490, 1107, 1491, 1108, 1534, 1165, 1669, 1064, 1376, 1063, 1755, 1756, 1190, 600, 601, 139, 1900]\n",
      "updated size: 1155\n",
      "iteration 10\n",
      "extracted cycle: [1140, 1582, 1141, 1616, 450, 1727, 1728, 905, 858, 832, 819, 807, 386, 1307, 809, 823]\n",
      "updated size: 1139\n",
      "iteration 11\n",
      "extracted cycle: [389, 1316, 991, 904, 550, 548, 1297, 110, 1554, 41, 1563, 1134, 1193, 1766, 148, 1615, 149, 35, 1412, 413, 1498, 1112, 958, 135, 680, 1659, 1157, 1646, 272, 861, 909, 1002]\n",
      "updated size: 1107\n",
      "iteration 12\n",
      "extracted cycle: [1070, 1397, 1075, 1418, 1419, 1420, 1421, 1076, 89, 882, 952, 1765, 166, 1935]\n",
      "updated size: 1093\n",
      "iteration 13\n",
      "extracted cycle: [1959, 872, 930, 108, 1285, 1024, 1286, 757, 410, 772, 771, 770, 769, 768, 766, 1473, 38, 620, 1729, 1181, 1717, 1718, 691, 132, 1564, 965, 92, 1123, 1527, 1528, 1529, 36, 1442, 1088, 1591, 1592, 1593, 1594, 445, 1542, 2, 1131, 1553, 1050, 1354, 760, 758, 1844, 1845, 840, 824, 263, 654, 656, 1711, 969, 1136, 1609, 1610, 1015, 1261, 177, 56, 594, 595, 1443, 628, 630, 340, 1130, 341, 1923, 1924, 875, 937, 1703, 160, 1707, 1708, 1179, 1709, 1710, 893, 849, 834, 1093, 1464, 1463, 1462, 418, 808, 821, 1517, 1518, 140, 733, 11, 3, 1531, 1532, 1533, 417, 1437, 1085, 1436, 1435, 959, 936, 1052, 1359, 130, 1713, 1714, 788, 787, 106, 1269, 524, 247, 391, 1092, 1556, 1557, 1558, 1559]\n",
      "updated size: 968\n",
      "iteration 14\n",
      "extracted cycle: [785, 510, 333, 1096, 1458, 1081, 1432, 589, 588, 84, 994, 906, 1885, 1884, 1221, 1775, 1196, 1856, 854, 725, 248, 563, 1329, 117, 306, 1773, 1195, 1774]\n",
      "updated size: 940\n",
      "iteration 15\n",
      "extracted cycle: [1958, 1028, 1301, 1302, 113, 1109, 1493]\n",
      "updated size: 933\n",
      "iteration 16\n",
      "extracted cycle: [812, 825, 841, 874, 1640, 1189, 1744, 28, 681, 682, 122, 1375, 1062, 1060, 1374, 138, 1816, 1815, 712, 373, 1051, 1355, 1356, 415, 1425, 426, 1488, 1489, 1188, 1743, 164, 1779, 968, 1117, 1510, 1116, 1874, 1875, 1876, 496, 1871]\n",
      "updated size: 892\n",
      "iteration 17\n",
      "iteration 18\n",
      "extracted cycle: [178, 287, 926, 1036, 1535]\n",
      "updated size: 885\n",
      "iteration 19\n",
      "extracted cycle: [765, 764, 1611, 1053, 1362, 443, 1758, 707, 706]\n",
      "updated size: 876\n",
      "iteration 20\n",
      "extracted cycle: [918, 1020, 1483, 1482, 136, 1481, 1480, 424, 1479, 39, 637, 86, 1638, 1639, 155, 857, 831, 686, 262, 33, 1368, 1057, 1369, 1370, 1058, 37, 1453, 1095, 332, 1585]\n",
      "updated size: 846\n",
      "iteration 21\n",
      "extracted cycle: [529, 530, 199, 708, 61, 256, 796, 901, 855, 1249, 102, 1080, 1570, 14, 1577, 651, 650, 16, 1586, 1587, 1588]\n",
      "updated size: 825\n",
      "iteration 22\n"
     ]
    }
   ],
   "source": [
    "def has_hamiltonian_path_via_cycle(G, A, cycle_nodes, B):\n",
    "    return any(G.has_edge(A, node) for node in cycle_nodes) and any(G.has_edge(B, node) for node in cycle_nodes)\n",
    "\n",
    "def contract_cycle_via_posa(G, cycles):\n",
    "    mapping = {}\n",
    "    valid_cycles = {}\n",
    "    for i, cycle in enumerate(cycles):\n",
    "        s_node = f\"supernode_{i}\"\n",
    "        for node in cycle:\n",
    "            mapping[node] = s_node\n",
    "        valid_cycles[s_node] = cycle\n",
    "    H = nx.Graph()\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        new_u = mapping.get(u, u)\n",
    "        new_v = mapping.get(v, v)\n",
    "        if new_u != new_v:\n",
    "            H.add_edge(new_u, new_v, **data)\n",
    "    to_contract = []\n",
    "    for node in list(H.nodes()):\n",
    "        if isinstance(node, str) and node.startswith(\"supernode_\"):\n",
    "            nbrs = list(H.neighbors(node))\n",
    "            if len(nbrs) == 2:\n",
    "                A, B = nbrs\n",
    "                if has_hamiltonian_path_via_cycle(G, A, valid_cycles[node], B):\n",
    "                    to_contract.append((node, A, B))\n",
    "    for s_node, A, B in to_contract:\n",
    "        if H.has_node(s_node):\n",
    "            H.remove_node(s_node)\n",
    "            H.add_edge(A, B)\n",
    "    return H\n",
    "\n",
    "def chain_contraction_preserving(G):\n",
    "    H = G.copy()\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        for node in list(H.nodes()):\n",
    "            if isinstance(node, str) and node.startswith(\"supernode_\"):\n",
    "                continue\n",
    "            if H.degree(node) == 2:\n",
    "                nbrs = list(H.neighbors(node))\n",
    "                if len(nbrs) == 2:\n",
    "                    A, B = nbrs\n",
    "                    H.remove_node(node)\n",
    "                    H.add_edge(A, B)\n",
    "                    changed = True\n",
    "    return H\n",
    "\n",
    "def perturbation_reduction(G):\n",
    "    n_threshold = np.log(G.number_of_nodes()) * 50\n",
    "    contracted = G.copy()\n",
    "    new_contracted = nx.Graph()\n",
    "    while abs(contracted.number_of_nodes() - new_contracted.number_of_nodes()) < n_threshold:\n",
    "        cycles = pathfinders.greedy_partial_cycle_extractor(contracted, {})  # You may pass fiedler info if available.\n",
    "        contracted = contract_cycle_via_posa(contracted, cycles) if cycles else contracted.copy()\n",
    "        new_contracted = chain_contraction_preserving(contracted)\n",
    "    return new_contracted\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    G = nx.erdos_renyi_graph(100, 0.05)\n",
    "    # In a symmetric graph the Fiedler vector is generally centered; if desired,\n",
    "    # you can take absolute values for ranking. Adjust based on your needs.\n",
    "    G_reduced = perturbation_reduction(G)\n",
    "    print(\"Nodes:\", list(G_reduced.nodes()))\n",
    "    print(\"Edges:\", list(G_reduced.edges()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph named 'Petersen Graph' with 10 nodes and 15 edges\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, graph \u001b[38;5;129;01min\u001b[39;00m nonham_tests:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(graph)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     results.append(\u001b[43mperturbation_reduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mperturbation_reduction\u001b[39m\u001b[34m(G)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m np.abs(old_contracted.number_of_nodes()-new_contracted.number_of_nodes())<\u001b[32m100\u001b[39m*np.log(n):\n\u001b[32m     13\u001b[39m     extracted_cycles = loop_extract(G, old_contracted, n)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     contracted = \u001b[43mcontract_cycles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextracted_cycles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     new_contracted = proc.chain_contraction_preserving(contracted)\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_contracted\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mcontract_cycles\u001b[39m\u001b[34m(G, cycles)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, cycle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cycles):\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# Create a label for the supernode representing the cycle.\u001b[39;00m\n\u001b[32m      6\u001b[39m     supernode = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msupernode_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msupernode\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# For nodes not included in any cycle, map them to themselves.\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for name, graph in nonham_tests:\n",
    "    print(graph)\n",
    "    results.append(perturbation_reduction(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def extract_frontier(cycle_nodes, all_nodes_set, ncache):\n",
    "    return {(u, v) for u in cycle_nodes for v in (all_nodes_set - ncache[u]) }\n",
    "\n",
    "def compute_frontier_quality(G, cycle_nodes, all_nodes_set, ncache, deg_cache):\n",
    "    frontier = extract_frontier(cycle_nodes, all_nodes_set, ncache)\n",
    "    if not frontier:\n",
    "        return 0.0, frontier\n",
    "    frontier_fraction = len(frontier) / len(cycle_nodes)\n",
    "    total_deg = sum(deg_cache.get(u, 0) for u, _ in frontier)\n",
    "    avg_frontier_deg = total_deg / len(frontier)\n",
    "    quality = frontier_fraction * avg_frontier_deg\n",
    "    return quality, frontier\n",
    "\n",
    "def greedy_fiedler_cycle_extractor_stop_at_threshold(G, fiedler, min_cycle_size=40, lower_cycle_bound=20, min_frontier_quality_factor=0.4):\n",
    "    cycles, frontiers_list, stray_paths = [], [], []\n",
    "    visited_global = set()\n",
    "    nodes = list(G.nodes())\n",
    "    all_nodes_set = set(nodes)\n",
    "    ncache = {node: set(G.neighbors(node)) for node in nodes}\n",
    "    deg_cache = {node: G.degree(node) for node in nodes}\n",
    "    fiedler_map = dict(zip(nodes, fiedler))\n",
    "    avg_deg_G = sum(deg_cache.values()) / len(deg_cache)\n",
    "    quality_threshold = min_frontier_quality_factor * avg_deg_G\n",
    "    for start in nodes:\n",
    "        if start in visited_global:\n",
    "            continue\n",
    "        path = [start]\n",
    "        visited_local = {start}\n",
    "        current = start\n",
    "        candidate_cycle = None\n",
    "        candidate_frontier = None\n",
    "        while True:\n",
    "            best_diff, next_node = float('inf'), None\n",
    "            for nbr in G.neighbors(current):\n",
    "                if nbr not in visited_local:\n",
    "                    diff = abs(fiedler_map.get(nbr, 0) - fiedler_map.get(current, 0))\n",
    "                    if diff < best_diff:\n",
    "                        best_diff, next_node = diff, nbr\n",
    "            if next_node is None:\n",
    "                break\n",
    "            path.append(next_node)\n",
    "            visited_local.add(next_node)\n",
    "            current = next_node\n",
    "            if len(path) >= lower_cycle_bound and G.has_edge(current, start):\n",
    "                quality, frontier = compute_frontier_quality(G, path, all_nodes_set, ncache, deg_cache)\n",
    "                if quality >= quality_threshold:\n",
    "                    candidate_cycle = path + [start]\n",
    "                    candidate_frontier = frontier\n",
    "                    break\n",
    "            if len(path) >= min_cycle_size and G.has_edge(current, start):\n",
    "                candidate_cycle = path + [start]\n",
    "                candidate_frontier = frontier\n",
    "                break\n",
    "        if candidate_cycle is not None:\n",
    "            cycles.append(candidate_cycle)\n",
    "            frontiers_list.append(candidate_frontier)\n",
    "            visited_global.update(path)\n",
    "        else:\n",
    "            stray_paths.append(path)\n",
    "            visited_global.update(path)\n",
    "    stray_vertices = all_nodes_set - visited_global\n",
    "    residual = {\"paths\": stray_paths, \"vertices\": stray_vertices}\n",
    "    return cycles, frontiers_list, residual\n",
    "\n",
    "def augment_frontiers(G, frontiers_list, residual):\n",
    "    residual_frontiers = []\n",
    "    print(len(residual.items()))\n",
    "    for path in residual.get(\"paths\", []):\n",
    "        path_set = set(path)\n",
    "        res_f = set()\n",
    "        for u in path:\n",
    "            for nbr in G.neighbors(u):\n",
    "                if nbr not in path_set:\n",
    "                    res_f.add((u, nbr))\n",
    "        print(f\"residual path {path} frontier: {res_f}\")\n",
    "        residual_frontiers.append(res_f)\n",
    "    stray_frontiers = []\n",
    "    for node in residual.get(\"vertices\", set()):\n",
    "        res_f = {(node, nbr) for nbr in G.neighbors(node)}\n",
    "        print(f\"residual vertex {node} frontier: {res_f}\")\n",
    "        stray_frontiers.append(res_f)\n",
    "    aug = frontiers_list.copy()\n",
    "    aug.extend(residual_frontiers)\n",
    "    aug.extend(stray_frontiers)\n",
    "    return aug\n",
    "\n",
    "def create_whole_mapping(cycles, residual):\n",
    "    mapping = {}\n",
    "    for i, cycle in enumerate(cycles):\n",
    "        label = f\"c{i}\"\n",
    "        nodes = set(cycle[:-1]) if cycle[0] == cycle[-1] else set(cycle)\n",
    "        for node in nodes:\n",
    "            mapping[node] = label\n",
    "    for i, path in enumerate(residual.get(\"paths\", [])):\n",
    "        label = f\"r{i}\"\n",
    "        for node in path:\n",
    "            mapping[node] = label\n",
    "    for node in residual.get(\"vertices\", set()):\n",
    "        mapping[node] = f\"s_{node}\"\n",
    "    return mapping\n",
    "\n",
    "def neighbor_cache_from_graph(G):\n",
    "    return {node: set(G.neighbors(node)) for node in G.nodes()}\n",
    "\n",
    "def recompute_frontier_cached(nodes, G, ncache):\n",
    "    f = set()\n",
    "    for u in nodes:\n",
    "        for v in ncache[u]:\n",
    "            if v not in nodes:\n",
    "                f.add((u, v))\n",
    "    return f\n",
    "\n",
    "def create_supernodes(cycles, residual, G):\n",
    "    mapping = create_whole_mapping(cycles, residual)\n",
    "    clusters = {}\n",
    "    for node, label in mapping.items():\n",
    "        clusters.setdefault(label, set()).add(node)\n",
    "    ncache = neighbor_cache_from_graph(G)\n",
    "    supernodes = {}\n",
    "    for label, nodes in clusters.items():\n",
    "        f = recompute_frontier_cached(nodes, G, ncache)\n",
    "        supernodes[label] = {\"label\": label, \"nodes\": nodes, \"frontier\": f, \"cycle\": None}\n",
    "    return list(supernodes.values()), mapping\n",
    "\n",
    "def connections_from_frontiers(frontiers, mapping):\n",
    "    connd = {}\n",
    "    for frontier in frontiers:\n",
    "        for u, v in frontier:\n",
    "            src = mapping.get(u)\n",
    "            tgt = mapping.get(v)\n",
    "            if src is None or tgt is None or src == tgt:\n",
    "                continue\n",
    "            key = tuple(sorted((src, tgt)))\n",
    "            connd.setdefault(key, []).append((u, v))\n",
    "    return connd\n",
    "\n",
    "def candidate_edges_between(snA, snB):\n",
    "    return [edge for edge in snA[\"frontier\"] if edge[1] in snB[\"nodes\"]]\n",
    "\n",
    "def merge_supernodes(snA, snB, G, ncache):\n",
    "    merged_nodes = snA[\"nodes\"] | snB[\"nodes\"]\n",
    "    merged_cycle = snA[\"cycle\"] + snB[\"cycle\"][1:] if (snA.get(\"cycle\") and snB.get(\"cycle\")) else None\n",
    "    merged_frontier = recompute_frontier_cached(merged_nodes, G, ncache)\n",
    "    return {\"label\": None, \"nodes\": merged_nodes, \"cycle\": merged_cycle, \"frontier\": merged_frontier}\n",
    "\n",
    "def rotate_cycle_to(cycle, x):\n",
    "    idx = cycle.index(x)\n",
    "    new_cycle = cycle[idx:] + cycle[1:idx+1]\n",
    "    if new_cycle[0] != new_cycle[-1]:\n",
    "        new_cycle.append(new_cycle[0])\n",
    "    return new_cycle\n",
    "\n",
    "def sew_two_cycles(cycleA, cycleB, candidates):\n",
    "\n",
    "    if len(candidates) < 2:\n",
    "        raise ValueError(\"must provide at least two candidate edge pairs.\")\n",
    "    \n",
    "    a1, b1 = candidates[0]\n",
    "    a2, b2 = candidates[1]\n",
    "\n",
    "    A_rot = rotate_cycle_to(cycleA, a1)\n",
    "    B_rot = rotate_cycle_to(cycleB, b1)\n",
    "    \n",
    "    try:\n",
    "        idx_a2 = A_rot.index(a2)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Vertex {a2} not found in rotated cycle A.\")\n",
    "    \n",
    "    try:\n",
    "        idx_b2 = B_rot.index(b2)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Vertex {b2} not found in rotated cycle B.\")\n",
    "    new_cycle = A_rot[:idx_a2+1] + list(reversed(B_rot[:idx_b2+1]))\n",
    "    \n",
    "    if new_cycle[0] != new_cycle[-1]:\n",
    "        new_cycle.append(new_cycle[0])\n",
    "    return new_cycle\n",
    "\n",
    "def try_sew_cycle(cycleA, cycleB, cand_list):\n",
    "    for i in range(len(cand_list)):\n",
    "        for j in range(i+1, len(cand_list)):\n",
    "            try:\n",
    "                sewn_cycle = sew_two_cycles(cycleA, cycleB, [cand_list[i], cand_list[j]])\n",
    "                return sewn_cycle\n",
    "            except Exception:\n",
    "                continue\n",
    "    return None\n",
    "\n",
    "def iterative_sewing(supernodes, connection_dict, G, mapping):\n",
    "    sn_map = {sn[\"label\"]: sn for sn in supernodes}\n",
    "    ncache = neighbor_cache_from_graph(G)\n",
    "    heap = []\n",
    "    for key, cand in connection_dict.items():\n",
    "        if len(cand) >= 2:\n",
    "            heapq.heappush(heap, (len(cand), key, cand))\n",
    "    while heap:\n",
    "        cost, (l1, l2), cand_list = heapq.heappop(heap)\n",
    "        if l1 not in sn_map or l2 not in sn_map:\n",
    "            continue\n",
    "        cycleA = sn_map[l1][\"cycle\"]\n",
    "        cycleB = sn_map[l2][\"cycle\"]\n",
    "        new_cycle = try_sew_cycle(cycleA, cycleB, cand_list)\n",
    "        if new_cycle is None:\n",
    "            continue\n",
    "        new_label = f\"{l1}+{l2}\"\n",
    "        # Instead of using only new_cycle's nodes, store the union of the two merged supernodes\n",
    "        new_nodes = sn_map[l1][\"nodes\"] | sn_map[l2][\"nodes\"]\n",
    "        new_supernode = {\n",
    "            \"label\": new_label,\n",
    "            \"cycle\": new_cycle,\n",
    "            \"nodes\": new_nodes,\n",
    "            \"frontier\": recompute_frontier_cached(new_nodes, G, ncache)\n",
    "        }\n",
    "        for node in new_supernode[\"nodes\"]:\n",
    "            mapping[node] = new_label\n",
    "        del sn_map[l1]\n",
    "        del sn_map[l2]\n",
    "        sn_map[new_label] = new_supernode\n",
    "        keys_to_remove = [k for k in connection_dict if l1 in k or l2 in k]\n",
    "        for k in keys_to_remove:\n",
    "            del connection_dict[k]\n",
    "        for other in sn_map:\n",
    "            if other == new_label:\n",
    "                continue\n",
    "            new_cand = candidate_edges_between(new_supernode, sn_map[other])\n",
    "            if new_cand and len(new_cand) >= 2:\n",
    "                key = tuple(sorted((new_label, other)))\n",
    "                connection_dict[key] = new_cand\n",
    "        heap = []\n",
    "        for key, cand in connection_dict.items():\n",
    "            if len(cand) >= 2:\n",
    "                heapq.heappush(heap, (len(cand), key, cand))\n",
    "    return list(sn_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_core_sewing(G, fiedler, min_cycle_size=40, lower_cycle_bound=20, min_frontier_quality_factor=0.4):\n",
    "    cycles, frontiers, residual = greedy_fiedler_cycle_extractor_stop_at_threshold(G, fiedler, min_cycle_size, min_frontier_quality_factor)\n",
    "    # we only use the cycles for core sewing  we ignore residuals -- may be interesting to integrate residuals for certain density thresholds ?\n",
    "    mapping = create_whole_mapping(cycles, {\"paths\": [], \"vertices\": set()})\n",
    "    supernodes, mapping = create_supernodes(cycles, {\"paths\": [], \"vertices\": set()}, G)\n",
    "    connection_dict = connections_from_frontiers(frontiers, mapping)\n",
    "    sewn_supernodes = iterative_sewing(supernodes, connection_dict, G, mapping)\n",
    "    if sewn_supernodes:\n",
    "        final_supernode = max(sewn_supernodes, key=lambda sn: len(sn[\"nodes\"]))\n",
    "    else:\n",
    "        final_supernode = None\n",
    "    return final_supernode, residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_suspectham(G):\n",
    "    A = se.to_adjacency(G)\n",
    "    _,fiedler,_ = se.power_method(A)\n",
    "    return full_core_sewing(G, fiedler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = random.choice(ham_tests)\n",
    "final_core, residual = test_suspectham(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paths': [], 'vertices': set()}\n"
     ]
    }
   ],
   "source": [
    "print(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
